{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faezesarlakifar/ChillinWars-Agent/blob/main/GeneticMiniMax_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Df2ZXWS2mWL"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "# chillin imports\n",
        "from chillin_client import RealtimeAI\n",
        "\n",
        "# project imports\n",
        "from ks.models import ECell, EDirection, Position\n",
        "from ks.commands import ChangeDirection, ActivateWallBreaker\n",
        "\n",
        "# Constants\n",
        "POPULATION_SIZE = 100\n",
        "MAX_GENERATIONS = 500\n",
        "MAX_DEPTH = 3\n",
        "MUTATION_RATE = 0.1\n",
        "\n",
        "class AI(RealtimeAI):\n",
        "\n",
        "    def __init__(self, world):\n",
        "        super(AI, self).__init__(world)\n",
        "        self.world = world\n",
        "\n",
        "    def initialize(self):\n",
        "        print('initialize')\n",
        "\n",
        "    def decide(self):\n",
        "        print('decide')\n",
        "        self.client1()\n",
        "\n",
        "    def client1(self):\n",
        "        state = self.world  # Initial state\n",
        "        my_team = self.my_side\n",
        "\n",
        "        if self.world.agents[my_team].wall_breaker_cooldown == 0:\n",
        "            self.send_command(ActivateWallBreaker())\n",
        "        best_direction = self.genetic_minimax(state, MAX_GENERATIONS, POPULATION_SIZE)\n",
        "        print(best_direction)\n",
        "        self.send_command(ChangeDirection(best_direction))\n",
        "\n",
        "    def genetic_minimax(self, state, max_generations, population_size):\n",
        "        population = self.initialize_population(population_size)\n",
        "        max_ = float('-inf')\n",
        "        best_action = population[0][0]\n",
        "        for _ in range(max_generations):\n",
        "            fitness_scores = []\n",
        "            for individual in population:\n",
        "                fitness_score = self.evaluate_individual(state, individual)\n",
        "                fitness_scores.append(fitness_score)\n",
        "                if fitness_score > max_:\n",
        "                    max = fitness_score\n",
        "                    best_action = individual[0]\n",
        "\n",
        "            population = self.select_parents(population, fitness_scores, population_size)\n",
        "            population = self.crossover(population, population_size)\n",
        "            population = self.mutate(population)\n",
        "            \n",
        "        #sorted_population = [ind for _, ind in sorted(enumerate(population), key=lambda x: fitness_scores[x[0]])]\n",
        "        #best_individual = sorted_population[0]\n",
        "        \n",
        "        #best_action = best_individual[0]\n",
        "    \n",
        "        return best_action\n",
        "\n",
        "    def initialize_population(self, population_size):\n",
        "      population = []\n",
        "      directions = list(EDirection)\n",
        "      for _ in range(population_size):\n",
        "          individual = [random.choice(directions)]\n",
        "          for _ in range(MAX_DEPTH - 1):\n",
        "              previous_direction = individual[-1]\n",
        "              valid_directions = [direction for direction in directions if not self.is_opposite(previous_direction, direction)]\n",
        "              individual.append(random.choice(valid_directions))\n",
        "          population.append(individual)\n",
        "      return population\n",
        "\n",
        "    def mutate(self, population):\n",
        "        for i in range(len(population)):\n",
        "            for j in range(MAX_DEPTH):\n",
        "                if random.random() < MUTATION_RATE:\n",
        "                    previous_direction = population[i][j-1]\n",
        "                    valid_directions = [direction for direction in list(EDirection) if not self.is_opposite(previous_direction, direction)]\n",
        "                    population[i][j] = random.choice(valid_directions)\n",
        "        return population\n",
        "\n",
        "    def is_opposite(self, direction1, direction2):\n",
        "        if (direction1 == EDirection.Up and direction2 == EDirection.Down) or \\\n",
        "                (direction1 == EDirection.Down and direction2 == EDirection.Up) or \\\n",
        "                (direction1 == EDirection.Left and direction2 == EDirection.Right) or \\\n",
        "                (direction1 == EDirection.Right and direction2 == EDirection.Left):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def evaluate_individual(self, state, individual):\n",
        "        total_score = 0\n",
        "        current_state = copy.deepcopy(state)\n",
        "        for direction in individual:\n",
        "            next_state, flag = self.get_next_state(current_state, direction)\n",
        "            total_score += self.evaluate_state(next_state, flag)\n",
        "            current_state = next_state\n",
        "        return total_score\n",
        "\n",
        "    # def select_parents(self, population, fitness_scores, population_size):\n",
        "    #     selected_population = []\n",
        "    #     sorted_population = [ind for _, ind in sorted(zip(fitness_scores, population))]\n",
        "    #     selected_population.extend(sorted_population[:population_size])\n",
        "    #     return selected_population\n",
        "    def select_parents(self, population, fitness_scores, population_size):\n",
        "        sorted_population = [ind for _, ind in sorted(enumerate(population), key=lambda x: fitness_scores[x[0]])]\n",
        "        selected_population = sorted_population[:population_size]\n",
        "        return selected_population\n",
        "\n",
        "    def crossover(self, population, population_size):\n",
        "        new_population = []\n",
        "        for _ in range(population_size):\n",
        "            parent1 = random.choice(population)\n",
        "            parent2 = random.choice(population)\n",
        "            crossover_point = random.randint(1, MAX_DEPTH - 1)\n",
        "            child = parent1[:crossover_point] + parent2[crossover_point:]\n",
        "            new_population.append(child)\n",
        "        return new_population\n",
        "\n",
        "    def _get_our_agent_position(self, state):\n",
        "        return state.agents[self.my_side].position\n",
        "\n",
        "    def _get_their_agent_position(self, state):\n",
        "        return state.agents[self.other_side].position\n",
        "\n",
        "    def evaluate_state(self, state, flag__):\n",
        "        \n",
        "        if(flag__):\n",
        "            return float('-inf')\n",
        "      \n",
        "        max_cycles = self.world.constants.max_cycles\n",
        "        wall_score_coefficient = self.world.constants.wall_score_coefficient\n",
        "        my_wall_crash_score = self.world.constants.my_wall_crash_score\n",
        "        enemy_wall_crash_score = self.world.constants.enemy_wall_crash_score\n",
        "\n",
        "        my_agent = state.agents[self.my_side]\n",
        "        \n",
        "        # Check if the direction can not be done\n",
        "        if my_agent.position.x >= len(state.board[0]):\n",
        "            return float('-inf')\n",
        "        \n",
        "        if my_agent.position.y >= len(state.board):\n",
        "            return float('-inf')\n",
        "        \n",
        "        if state.board[my_agent.position.y][my_agent.position.x] == ECell.AreaWall :\n",
        "            my_agent.health = 0\n",
        "            return float('-inf')\n",
        "        \n",
        "        opponent_agent = state.agents[self.other_side]\n",
        "\n",
        "        my_score = state.scores[self.my_side]\n",
        "        opponent_score = state.scores[self.other_side]\n",
        "        \n",
        "        current_cycle = self.current_cycle\n",
        "        \n",
        "        score_diff = my_score - opponent_score\n",
        "\n",
        "        my_wall_penalty = 0\n",
        "        enemy_wall_penalty = 0\n",
        "        wall_coefficient_reward = 0\n",
        "\n",
        "        # Compute the penalties for hitting walls\n",
        "        if(self.my_side == 'Yellow'):\n",
        "          if state.board[my_agent.position.y][my_agent.position.x] == ECell.YellowWall :\n",
        "              my_wall_penalty = my_wall_crash_score\n",
        "              if(my_agent.wall_breaker_rem_time < 1):\n",
        "                my_agent.health -= 1\n",
        "          elif state.board[my_agent.position.y][my_agent.position.x] == ECell.BlueWall :\n",
        "              enemy_wall_penalty = enemy_wall_crash_score\n",
        "              if(my_agent.wall_breaker_rem_time < 1):\n",
        "                my_agent.health -= 1\n",
        "        else:\n",
        "          if state.board[my_agent.position.y][my_agent.position.x] == ECell.YellowWall :\n",
        "              enemy_wall_penalty = enemy_wall_crash_score\n",
        "              if(my_agent.wall_breaker_rem_time < 1):\n",
        "                my_agent.health -= 1\n",
        "          elif state.board[my_agent.position.y][my_agent.position.x] == ECell.BlueWall :\n",
        "              my_wall_penalty = my_wall_crash_score\n",
        "              if(my_agent.wall_breaker_rem_time < 1):\n",
        "                my_agent.health -= 1\n",
        "\n",
        "        if state.board[my_agent.position.y][my_agent.position.x] == ECell.Empty :\n",
        "        # if my_agent.position in empty_neighbors:\n",
        "            wall_coefficient_reward = wall_score_coefficient*10\n",
        "        # Compute the score for the state\n",
        "        state_score = score_diff + my_wall_penalty + enemy_wall_penalty + wall_coefficient_reward + my_agent.health\n",
        "\n",
        "        # Check if the game is over\n",
        "        if current_cycle >= max_cycles or my_agent.health <= 0 or opponent_agent.health <= 0 or ((my_agent.position.x == opponent_agent.position.x) and (my_agent.position.y == opponent_agent.position.y)) :\n",
        "            # Return a higher value for a better state and a lower value for a worse state\n",
        "            if my_score > opponent_score:\n",
        "                return float('inf')\n",
        "            elif my_score < opponent_score:\n",
        "                return float('-inf')\n",
        "            else:\n",
        "                return 0\n",
        "\n",
        "        # Evaluate the quality of the state based on the score difference\n",
        "\n",
        "        return state_score\n",
        "\n",
        "    def get_next_state(self, state, direction):\n",
        "        \n",
        "        next_state = copy.deepcopy(state)\n",
        "        current_agent = copy.deepcopy(state.agents[self.my_side])\n",
        "        \n",
        "        #apply direction to the state and make virtual next state\n",
        "        \n",
        "        # update state board ----> applied on evaluate_state function\n",
        "        \n",
        "        flag_ = False\n",
        "        # update state agents\n",
        "        if (current_agent.direction == EDirection.Up):\n",
        "            if(direction == EDirection.Down):\n",
        "                flag_ = True\n",
        "        elif (current_agent.direction == EDirection.Down):\n",
        "            if(direction == EDirection.Up):\n",
        "                flag_ = True\n",
        "        if (current_agent.direction == EDirection.Right):\n",
        "            if(direction == EDirection.Left):\n",
        "                flag_ = True\n",
        "        elif (current_agent.direction == EDirection.Left):\n",
        "            if(direction == EDirection.Right):\n",
        "                flag_ = True\n",
        "                \n",
        "        if(direction == EDirection.Up):\n",
        "            current_agent.position.y -= 1\n",
        "            current_agent.direction = EDirection.Up\n",
        "        elif(direction == EDirection.Down):  \n",
        "            current_agent.position.y += 1\n",
        "            current_agent.direction = EDirection.Down\n",
        "        elif(direction == EDirection.Right): \n",
        "            current_agent.position.x += 1\n",
        "            current_agent.direction = EDirection.Right\n",
        "        elif(direction == EDirection.Left):\n",
        "            current_agent.position.x -= 1\n",
        "            current_agent.direction = EDirection.Left\n",
        "            \n",
        "        next_state.agents[self.my_side] = current_agent\n",
        "        \n",
        "        # update state scores ----> applied on evaluate_state function\n",
        "        \n",
        "        return next_state, flag_\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMixBA5vcqbkYowLE5ZDSV0",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
